{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P_zD7hGruQA",
        "outputId": "edc882c0-d589-4d06-bbe8-d775d7c0cb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Cloning into 'iPLAN-Interactive-and-Procedural-Layout-Planning'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (210/210), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 301 (delta 96), reused 106 (delta 46), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (301/301), 12.98 MiB | 16.82 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Directory di lavoro corrente: /content\n",
            "Nuova directory di lavoro: /content/iPLAN-Interactive-and-Procedural-Layout-Planning\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!git clone https://github.com/realcrane/iPLAN-Interactive-and-Procedural-Layout-Planning\n",
        "\n",
        "import os\n",
        "print(\"Directory di lavoro corrente:\", os.getcwd())\n",
        "roomType_directory = '/content/iPLAN-Interactive-and-Procedural-Layout-Planning/'\n",
        "os.chdir(roomType_directory)\n",
        "print(\"Nuova directory di lavoro:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from synth.floorplan.roomtype_fp import FloorPlan\n",
        "from room_type import models\n",
        "import scipy.io as sio"
      ],
      "metadata": {
        "id": "L547UbNXr2sp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getList(path):\n",
        "  mat_list = os.listdir(path)\n",
        "  mat_list.sort()\n",
        "  temp_list = []\n",
        "  for name in mat_list[:]: #Correzione\n",
        "      mat_path = os.path.join(path, name)\n",
        "      data = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)['data']\n",
        "      if type(data.rTypes) is not np.ndarray or len(data.rTypes) == 0:\n",
        "          temp_list.append(name)\n",
        "\n",
        "  return temp_list"
      ],
      "metadata": {
        "id": "AmMOhP3Er5Sn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROOM TYPE\n"
      ],
      "metadata": {
        "id": "OWd4PuJasJDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_room_per_type = [1, 2, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1]\n",
        "max_room_num = np.sum(np.array(max_room_per_type))\n",
        "noise_dim = 32\n",
        "load_cvae_path = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_type/roomtype_cvae_150.pth\"\n",
        "\n",
        "# step1: configure model\n",
        "print('Building model...')\n",
        "cvae = models.cvae(\n",
        "    modul_name='roomtype',\n",
        "    model_name='cvae',\n",
        "    input_dim=max_room_num,\n",
        "    hidden_dim1=128,\n",
        "    hidden_dim2=64,\n",
        "    z_dim=noise_dim\n",
        ")\n",
        "print(cvae)\n",
        "\n",
        "cvae.load_model(load_cvae_path)\n",
        "cvae.cuda()\n",
        "\n",
        "# step2: data\n",
        "\n",
        "data_root = \"/content/iPLAN-Interactive-and-Procedural-Layout-Planning/data/test\"\n",
        "floorplans = getList(data_root)\n",
        "\n",
        "Input = []\n",
        "Output = []\n",
        "# step3: testing\n",
        "for i in range(len(floorplans)):\n",
        "  fp_name = floorplans[i]\n",
        "  fp_path = os.path.join(data_root, fp_name)\n",
        "  fp = FloorPlan(fp_path)\n",
        "\n",
        "  # if given room types\n",
        "  # fp.rTypes = fp.gt_rTypes\n",
        "  # fp.rBoxes = np.array([])\n",
        "  # fp.rCenters= np.array([])\n",
        "  # data = fp.to_dict()\n",
        "  # sio.savemat(fp_path, {'data': data})\n",
        "\n",
        "  input_img = fp.init_input_img(fp.exterior_boundary)\n",
        "  Input.append(input_img)\n",
        "  input_img = torch.FloatTensor(input_img).unsqueeze(0).unsqueeze(0).cuda()\n",
        "  input_img = fp.normalize(input_img)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    emb = cvae.embed(input_img)\n",
        "    z = torch.randn(input_img.size(0), 32).cuda()\n",
        "    o_z = torch.cat([z, emb], 1)\n",
        "    sample = cvae.decoder(o_z).cuda()\n",
        "    sample = sample.view(-1, 19)\n",
        "    fp.update_rTypes(sample.squeeze().cpu().numpy(), max_room_per_type)\n",
        "    fp.rBoxes = np.array([])\n",
        "    fp.rCenters = np.array([])\n",
        "    data = fp.to_dict()\n",
        "    Output.append(data)\n",
        "    #sio.savemat(fp_path, {'data': data})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J341D6Mhr5z-",
        "outputId": "e6b50ad3-b966-4991-ee67-ebbf2499b6b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n",
            "CVAE(\n",
            "  (fc1): Linear(in_features=83, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc31): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc32): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc4): Linear(in_features=96, out_features=96, bias=True)\n",
            "  (fc5): Linear(in_features=96, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=19, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (embed): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(16, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): Conv2d(16, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (16): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Risultati"
      ],
      "metadata": {
        "id": "Bf-7PleRs6tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for dictionary in Output:\n",
        "  for key, value in dictionary.items():\n",
        "    if key == \"rTypes\": print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoQKxNyAtAkN",
        "outputId": "07646c8c-1966-427a-c360-1e7739b1342f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 7 9]\n",
            "[0 1 2 3 7 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SALVATAGGIO DATI"
      ],
      "metadata": {
        "id": "bjyDBufYuWcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomType/0.mat\", {\"data\" : Output[0]})\n",
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomType/1.mat\",{\"data\" : Output[1]})"
      ],
      "metadata": {
        "id": "Ri_f4-hBuZHS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOCATING ROOM"
      ],
      "metadata": {
        "id": "uNDFs1BLsLd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_rcenters(center, rCenters):\n",
        "    flag = True\n",
        "    center = np.array(center)\n",
        "    for i in range(len(rCenters)):\n",
        "        temp = np.array(rCenters[i])\n",
        "        dist = np.linalg.norm(center - temp)\n",
        "        if dist < 9:\n",
        "            flag = False\n",
        "            return flag\n",
        "    return flag"
      ],
      "metadata": {
        "id": "JDmmCK_UsPpC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_center(predict, r_t, mask_size=4):\n",
        "    index_point = []\n",
        "    index = np.where(predict == r_t.cpu().numpy())\n",
        "    for ind in range(index[0].shape[0]):\n",
        "        index_point.append((index[0][ind], index[1][ind]))\n",
        "\n",
        "    num_point = 0\n",
        "    if len(index_point) > 0:\n",
        "        min_h = np.min(index[0])\n",
        "        min_w = np.min(index[1])\n",
        "        max_h = np.max(index[0])\n",
        "        max_w = np.max(index[1])\n",
        "\n",
        "        if max_h - min_h + 1 <= 2 * mask_size and max_w - min_w + 1 <= 2 * mask_size:\n",
        "            predict_h = (min_h + max_h) // 2\n",
        "            predict_w = (min_w + max_w) // 2\n",
        "            num_point = len(index_point)\n",
        "        else:\n",
        "            predict_h, predict_w = index_point[0]\n",
        "            for point in index_point:\n",
        "                new_num_point = 0\n",
        "                for other_point in index_point:\n",
        "                    if abs(other_point[0] - point[0]) <= mask_size and abs(\n",
        "                            other_point[1] - point[1]) <= mask_size:\n",
        "                        new_num_point += 1\n",
        "                if new_num_point > num_point:\n",
        "                    predict_h, predict_w = point\n",
        "                    num_point = new_num_point\n",
        "    if num_point > 0:\n",
        "        return np.array([predict_h, predict_w])\n",
        "    else:\n",
        "        return np.array([0, 0])"
      ],
      "metadata": {
        "id": "uN-qrfH5tKrQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rcenters(fp, location_model, location_connect, location_embedding, mask_size=4):\n",
        "    pred_rCenters = []\n",
        "    pred_rTypes = []\n",
        "\n",
        "    living_node = fp.living_node\n",
        "    h, w = living_node['centroid']\n",
        "    pred_rCenters.append(np.array([int(h), int(w)]))\n",
        "    pred_rTypes.append(0)\n",
        "\n",
        "    input_location = fp.get_composite_location(num_extra_channels=0)\n",
        "    continue_rTypes = fp.continue_rTypes.squeeze()\n",
        "    input_location = input_location.unsqueeze(0).cuda()\n",
        "\n",
        "    room_num = continue_rTypes.shape[0]\n",
        "\n",
        "    iter = 0\n",
        "    flag = True\n",
        "    while room_num > 0:\n",
        "        update_id = np.zeros(room_num, dtype=bool)\n",
        "        iter = iter + 1\n",
        "\n",
        "        np.random.shuffle(continue_rTypes)\n",
        "        with torch.no_grad():\n",
        "            for n in range(room_num):\n",
        "                score_model = location_model(input_location)\n",
        "                r_t = torch.LongTensor(continue_rTypes[n:n + 1]).cuda()\n",
        "                one_hot_label = torch.nn.functional.one_hot(r_t, num_classes=13)\n",
        "                score_embedding = location_embedding(one_hot_label.float())\n",
        "                score_temp = torch.cat([score_model, score_embedding], 1)\n",
        "                score_connect = location_connect(score_temp)\n",
        "\n",
        "                score_softmax = torch.softmax(score_connect, dim=1)\n",
        "                output = score_softmax.cpu().numpy()\n",
        "                predict = np.argmax(output, axis=1)[0]\n",
        "\n",
        "                center = find_center(predict, r_t)\n",
        "                h, w = center\n",
        "\n",
        "                if h == 0 or w == 0 or input_location[0, 0, h, w] == 0:\n",
        "                    continue\n",
        "\n",
        "                flag = check_rcenters(center, pred_rCenters)\n",
        "\n",
        "                if flag:\n",
        "                    pred_rCenters.append(np.array([h, w]))\n",
        "                    pred_rTypes.append(r_t.cpu().numpy().reshape(1)[0])\n",
        "                    update_id[n] = True\n",
        "                    min_h = max(h - mask_size, 0)\n",
        "                    max_h = min(h + mask_size, 128 - 1)\n",
        "                    min_w = max(w - mask_size, 0)\n",
        "                    max_w = min(w + mask_size, 128 - 1)\n",
        "                    input_location[0, r_t + 4, min_h:max_h + 1, min_w:max_w + 1] = 1.0\n",
        "                    input_location[0, 3, :, :] = input_location[0, 4:, :, :].sum(0)\n",
        "\n",
        "                    iter = 0\n",
        "\n",
        "        continue_rTypes = continue_rTypes[~update_id]\n",
        "        room_num = continue_rTypes.shape[0]\n",
        "\n",
        "        if iter > 5:\n",
        "            if room_num == 0:  # 0: all room centers are located, 1: one room missing, 2: two room missing\n",
        "                flag = True\n",
        "            else:\n",
        "                flag = False\n",
        "            break\n",
        "\n",
        "    return pred_rCenters, pred_rTypes, flag"
      ],
      "metadata": {
        "id": "f1PQ23JHtKpe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getListLR(path):\n",
        "  mat_list = os.listdir(path)\n",
        "  mat_list.sort()\n",
        "  temp_list = []\n",
        "  for name in mat_list[:]:\n",
        "      mat_path = os.path.join(path, name)\n",
        "      data = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)[\"data\"]\n",
        "      if len(data.rCenters) == 0:\n",
        "          temp_list.append(name)\n",
        "  return temp_list"
      ],
      "metadata": {
        "id": "8k21h8JjwAOm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from synth.floorplan.roomlocation_fp import FloorPlan\n",
        "from room_location.Living import models as living\n",
        "from room_location.Location import models as location"
      ],
      "metadata": {
        "id": "ixBeUcSHtKnZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_model_roomLocation_resnet = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/resnet18-5c106cde.pth\"\n",
        "\n",
        "path_model_roomLocation_location_resnet = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/location_resnet18_100.pth\"\n",
        "path_model_roomLocation_location_up = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/location_up1_100.pth\"\n",
        "path_model_roomLocation_location_embed = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/location_embed_100.pth\"\n",
        "\n",
        "path_model_roomLocation_living_fci = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/living_fc1_300.pth\"\n",
        "path_model_roomLocation_living_resnet = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_location/living_resnet18_300.pth\""
      ],
      "metadata": {
        "id": "OCmxSbiJtKlC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step1: configure model\n",
        "print('Building model...')\n",
        "living_model = living.model(\n",
        "    module_name=\"living\",\n",
        "    model_name=\"resnet18_fc1\",\n",
        "    input_channel=3,\n",
        "    output_channel=2,\n",
        "    pretrained=False,\n",
        ")\n",
        "living_connect = living.connect(\n",
        "    module_name=\"living\",\n",
        "    model_name=\"resnet18_fc1\",\n",
        "    input_channel=512,\n",
        "    output_channel=2,\n",
        "    reshape=True\n",
        ")\n",
        "\n",
        "load_living_model_path = path_model_roomLocation_living_resnet\n",
        "load_living_connect_path = path_model_roomLocation_living_fci\n",
        "living_model.load_model(load_living_model_path)\n",
        "living_connect.load_model(load_living_connect_path)\n",
        "living_model.cuda()\n",
        "living_connect.cuda()\n",
        "\n",
        "location_model = location.model(\n",
        "    module_name='location',\n",
        "    model_name='resnet18_up1',\n",
        "    input_channel=13 + 4,\n",
        "    output_channel=13 + 3,\n",
        "    pretrained=True,\n",
        "    pretrained_path= path_model_roomLocation_resnet\n",
        ")\n",
        "\n",
        "location_connect = location.connect(\n",
        "    module_name='location',\n",
        "    model_name='resnet18_up1',\n",
        "    input_channel=512,\n",
        "    output_channel=13 + 3,\n",
        "    reshape=False\n",
        ")\n",
        "location_embedding = location.embedding(\n",
        "    module_name='location',\n",
        "    model_name='resnet18_up1',\n",
        "    input_channel=13,\n",
        "    output_channel=256,\n",
        "    reshape=False\n",
        ")\n",
        "epoch = 100\n",
        "load_location_model_path = path_model_roomLocation_location_resnet\n",
        "load_location_connect_path = path_model_roomLocation_location_up\n",
        "load_location_embedding_path = path_model_roomLocation_location_embed\n",
        "\n",
        "location_model.load_model(load_location_model_path)\n",
        "location_connect.load_model(load_location_connect_path)\n",
        "location_embedding.load_model(load_location_embedding_path)\n",
        "location_model.cuda()\n",
        "location_connect.cuda()\n",
        "location_embedding.cuda()\n",
        "\n",
        "living_model.eval()\n",
        "living_connect.eval()\n",
        "location_model.eval()\n",
        "location_connect.eval()\n",
        "location_embedding.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA072LWFtKha",
        "outputId": "9933a3d0-a421-4a1c-dc36-8726d86f2a9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n",
            "load the pretrained model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=256, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "  )\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step2: data\n",
        "data_root = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomType\"\n",
        "floorplans = getListLR(data_root)\n",
        "print('The length of testing data is {}'.format(len(floorplans)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ZRUaRJtKfD",
        "outputId": "b94d0316-6bab-471f-d785-cc3f5463ea87"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of testing data is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step3: testing\n",
        "print('Starting to Testing...')\n",
        "total = 0\n",
        "Data = []\n",
        "for i in range(len(Output)):\n",
        "  fp_name = floorplans[i]\n",
        "  print(fp_name)\n",
        "  fp_path = os.path.join(data_root, fp_name)\n",
        "  print(fp_path)\n",
        "  fp = FloorPlan(fp_path)\n",
        "\n",
        "  input_living = fp.get_composite_living()\n",
        "  input_living = input_living.unsqueeze(0).cuda()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    score_model = living_model(input_living)\n",
        "    score_connect_living = living_connect(score_model)\n",
        "    living_center = torch.round(score_connect_living)\n",
        "    living_center = living_center.cpu().squeeze().numpy()\n",
        "\n",
        "  node = {}\n",
        "  node['category'] = int(0)\n",
        "  x = living_center[0]\n",
        "  y = living_center[1]\n",
        "  node['centroid'] = (int(x), int(y))\n",
        "  fp.add_room(node)\n",
        "  fp.living_node = node\n",
        "\n",
        "  iteration = 0\n",
        "  # the maximum sampling for room location\n",
        "  while iteration < 50:\n",
        "    iteration = iteration + 1\n",
        "    pred_rCenters, pred_rTypes, flag = get_rcenters(fp, location_model, location_connect, location_embedding)\n",
        "    if flag:\n",
        "      fp.update_rCenters(pred_rCenters, pred_rTypes)\n",
        "      data = fp.to_dict()\n",
        "      Data.append(data)\n",
        "      sio.savemat(fp_path, {'data': data})\n",
        "      total = total + 1\n",
        "      print('{}/{}, has processd {} '.format(i + 1, total, data['name']))\n",
        "      break\n",
        "\n",
        "print(f'{total} layouts')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQbAqJ9ItKc9",
        "outputId": "03532984-de1a-4e6a-8741-8ef8a34c5638"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to Testing...\n",
            "0.mat\n",
            "/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomType/0.mat\n",
            "1/1, has processd 0 \n",
            "1.mat\n",
            "/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomType/1.mat\n",
            "2/2, has processd 1 \n",
            "2 layouts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Risultati\n"
      ],
      "metadata": {
        "id": "iswcn3M4xl7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for data in Data:\n",
        "  for key, value in data.items():\n",
        "    if key == \"rCenters\": print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VoRhapltKSh",
        "outputId": "45f222ff-d91a-4d6f-ee63-a49f2023ccf6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 58  71]\n",
            " [ 93  48]\n",
            " [ 33  65]\n",
            " [ 72  43]\n",
            " [ 53  47]\n",
            " [108  78]]\n",
            "[[64 69]\n",
            " [79 33]\n",
            " [40 69]\n",
            " [36 52]\n",
            " [81 59]\n",
            " [39 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SALVATAGGIO DATI"
      ],
      "metadata": {
        "id": "fEwB9k7Hx-dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/LocationRoom/0.mat\", {\"data\" : Data[0]})\n",
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/LocationRoom/1.mat\",{\"data\" : Data[1]})"
      ],
      "metadata": {
        "id": "7GeW40gXyGOv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTITIONING ROOM"
      ],
      "metadata": {
        "id": "IRuLJ6VFsQTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_turning(pred_rBoxes, boundary, living_mask, criterion, opt):\n",
        "  lr = opt.lr\n",
        "  pred_rBoxes = torch.autograd.Variable(pred_rBoxes, requires_grad=True)\n",
        "  loss = criterion(pred_rBoxes, boundary, living_mask, opt)\n",
        "  loss.backward()\n",
        "  grad = pred_rBoxes.grad\n",
        "  pred_rBoxes = pred_rBoxes - lr * grad\n",
        "  return pred_rBoxes\n",
        "\n",
        "def get_ratio(layout):\n",
        "  spare_area = (layout == 16).sum()\n",
        "  inside_area = (layout < 13).sum() + spare_area\n",
        "  ratio = spare_area / inside_area\n",
        "  return ratio\n",
        "\n",
        "def obtain_living(layout, boundary):\n",
        "  living_mask = layout.clone()\n",
        "  living_mask[living_mask < 16] = 0\n",
        "  min_y, min_x = np.min(boundary[:, :2], 0)\n",
        "  max_y, max_x = np.max(boundary[:, :2], 0)\n",
        "  for h in range(int(min_x) - 5, int(max_x) + 5):\n",
        "    for w in range(int(min_y) - 5, int(max_y) + 5):\n",
        "      if living_mask[h, w] == 0 and living_mask[h + 1, w] == 16 and living_mask[h + 2, w] == 0:\n",
        "        living_mask[h + 1, w] = 0\n",
        "      elif living_mask[h, w] == 0 and living_mask[h + 1, w] == 16 and living_mask[h + 2, w] == 16 and living_mask[\n",
        "        h + 3, w] == 0:\n",
        "        living_mask[h + 1, w] = 0\n",
        "        living_mask[h + 2, w] = 0\n",
        "      elif living_mask[h, w] == 0 and living_mask[h + 1, w] == 16 and living_mask[h + 2, w] == 16 and living_mask[\n",
        "        h + 3, w] == 16 and living_mask[h + 4, w] == 0:\n",
        "        living_mask[h + 1, w] = 0\n",
        "        living_mask[h + 2, w] = 0\n",
        "        living_mask[h + 3, w] = 0\n",
        "\n",
        "      if living_mask[h, w] == 0 and living_mask[h, w + 1] == 16 and living_mask[h, w + 2] == 0:\n",
        "        living_mask[h, w + 1] = 0\n",
        "      elif living_mask[h, w] == 0 and living_mask[h, w + 1] == 16 and living_mask[h, w + 2] == 16 and living_mask[\n",
        "        h, w + 3] == 0:\n",
        "        living_mask[h, w + 1] = 0\n",
        "        living_mask[h, w + 2] = 0\n",
        "      elif living_mask[h, w] == 0 and living_mask[h, w + 1] == 16 and living_mask[h, w + 2] == 16 and living_mask[\n",
        "        h, w + 3] == 16 and living_mask[h, w + 4] == 0:\n",
        "        living_mask[h, w + 1] = 0\n",
        "        living_mask[h, w + 2] = 0\n",
        "        living_mask[h, w + 3] = 0\n",
        "  layout[living_mask==16]=0\n",
        "  index = torch.where(living_mask)\n",
        "  min_x, max_x = torch.min(index[0]),torch.max(index[0])\n",
        "  min_y, max_y = torch.min(index[1]), torch.max(index[1])\n",
        "  box = torch.stack([min_y, min_x, max_y, max_x]) / 127\n",
        "  return box, layout, living_mask/16\n",
        "\n",
        "def get_image(img, rBoxes, rTypes, inside, living_mask=None):\n",
        "  if not living_mask==None:\n",
        "    img[living_mask==1]=0\n",
        "  for r_i in range(len(rTypes)):\n",
        "    r_box = rBoxes[r_i, :] * 127\n",
        "    r_box = r_box.long()\n",
        "    r_type = rTypes[r_i]\n",
        "    mask = torch.zeros(inside.size())\n",
        "    mask[r_box[1]:r_box[3] + 1, r_box[0]:r_box[2] + 1] = 1\n",
        "    mask = mask * inside\n",
        "    img = img * (1 - mask) + mask * r_type\n",
        "  return img"
      ],
      "metadata": {
        "id": "dgDEz3O6sTHT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getListRP(path):\n",
        "    mat_list = os.listdir(path)\n",
        "    mat_list.sort()\n",
        "    temp_list = []\n",
        "    for name in mat_list[:]:\n",
        "        mat_path = os.path.join(path, name)\n",
        "        data = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)['data']\n",
        "        if len(data.rBoxes) == 0 and len(data.rCenters) !=0:\n",
        "            temp_list.append(name)\n",
        "    return temp_list"
      ],
      "metadata": {
        "id": "nZLGWYLwytsz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/iPLAN-Interactive-and-Procedural-Layout-Planning/room_partition')\n",
        "sys.path.append('/content/iPLAN-Interactive-and-Procedural-Layout-Planning/room_partition/models')"
      ],
      "metadata": {
        "id": "e9_pWJ4lytqg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from synth.floorplan.roompartition_fp import FloorPlan\n",
        "from room_partition.utils import colorize_mask\n",
        "from room_partition import models\n",
        "import argparse"
      ],
      "metadata": {
        "id": "VVM8XWwxytmk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "cartella_origine = '/content/iPLAN-Interactive-and-Procedural-Layout-Planning/room_partition/utils'\n",
        "cartella_destinazione = '/content/iPLAN-Interactive-and-Procedural-Layout-Planning/room_partition/models'\n",
        "\n",
        "shutil.move(cartella_origine, cartella_destinazione)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pYNLMwoSytg1",
        "outputId": "f6d4fd5a-12a9-4c2a-b53a-0c77246d9db3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/iPLAN-Interactive-and-Procedural-Layout-Planning/room_partition/models/utils'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from room_partition.models.loss_layer import LossFun"
      ],
      "metadata": {
        "id": "ZN1HnEcDytc8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttrDict(dict):\n",
        "    \"\"\"Classe wrapper per consentire l'accesso attributivo agli elementi del dizionario.\"\"\"\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return self[name]\n",
        "\n",
        "    def __setattr__(self, name, value):\n",
        "        self[name] = value"
      ],
      "metadata": {
        "id": "XhywzeydzUV7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = AttrDict({\n",
        "    'load_netG_path': '/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Model/room_partition/G_net_210.pth',\n",
        "    'max_iter': 200,\n",
        "    'gpu_ids': [0],\n",
        "    'lr': 10,\n",
        "    'coverage': 1,\n",
        "    'inside': 0.5,\n",
        "    'mutex': 0,\n",
        "    'root': '/content/iPLAN-Interactive-and-Procedural-Layout-Planning/data'\n",
        "})"
      ],
      "metadata": {
        "id": "OYzEfLBHzYUJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.floorplan_rnn_test import FloorPlanRNN"
      ],
      "metadata": {
        "id": "CYAex6eAzZwQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step1: configure model\n",
        "print('Building model...')\n",
        "fp_rnn = FloorPlanRNN(opt)\n",
        "fp_rnn.load_networks(opt)\n",
        "criterion = LossFun(device=fp_rnn.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHoQ3aqBzk3x",
        "outputId": "11b84164-2ae1-4773-fa9f-9b9a7c629cdd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n",
            "load the pretrained Mask generation model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step2: data\n",
        "print('Building dataset...')\n",
        "data_root = \"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/LocationRoom\"\n",
        "floorplans = getListRP(data_root)\n",
        "print('The length of testing data is {}'.format(len(floorplans)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An5vpx9AznBP",
        "outputId": "d31aab27-62ae-4f99-a582-232a8cbfc075"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building dataset...\n",
            "The length of testing data is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getMath(path, i ):\n",
        "  mat_list = os.listdir(path)\n",
        "  mat_list.sort()\n",
        "  temp_list = []\n",
        "  for name in mat_list[:]:\n",
        "    mat_path = os.path.join(path, name)\n",
        "    data = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)['data']\n",
        "    data.rTypes = np.array([1])\n",
        "    if name == \"0.mat\":\n",
        "      center = []\n",
        "      center.append([58,71])\n",
        "      data.rCenters = np.array(center)\n",
        "      if i == 0: return data\n",
        "    else:\n",
        "      center = []\n",
        "      center.append([64,69])\n",
        "      data.rCenters = np.array(center)\n",
        "      if i ==1: return data"
      ],
      "metadata": {
        "id": "OCfo0go70RAw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input(mat_path):\n",
        "  data = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)['data']\n",
        "\n",
        "  img = fp.init_input_img(fp.exterior_boundary)\n",
        "  h, w = img.shape\n",
        "  inside = np.zeros((h, h))\n",
        "  inside[img == 16] = 1\n",
        "  inside[img < 13] = 1\n",
        "  inside_mask = torch.from_numpy(inside)\n",
        "  img = torch.from_numpy(img)\n",
        "\n",
        "  #print(data.rTypes)\n",
        "  ind = data.rTypes == 0\n",
        "  # print(data.rTypes == 0)\n",
        "  ind = np.array(ind)\n",
        "  # print(ind)\n",
        "  # print(data.rCenters)\n",
        "  continue_rTypes = data.rTypes[~ind]\n",
        "  # print(continue_rTypes)\n",
        "  continue_rCenters = data.rCenters[~ind]\n",
        "  # print(continue_rCenters)\n",
        "\n",
        "  rCenters=[]\n",
        "  for i in range(len(continue_rTypes)):\n",
        "    r_c = np.zeros((128, 128))\n",
        "    c_x, c_y = continue_rCenters[i,:]\n",
        "    r_c[c_x - 1:c_x + 2, c_y - 1:c_y + 2] = 1\n",
        "    rCenters.append(r_c)\n",
        "\n",
        "  rCenters = np.stack(rCenters, 0)\n",
        "  rCenters = torch.FloatTensor(rCenters)\n",
        "\n",
        "  return img, rCenters, torch.from_numpy(continue_rTypes), inside_mask, data.Boundary"
      ],
      "metadata": {
        "id": "Q4Kde9gR0Rqs"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step3: testing\n",
        "Data = []\n",
        "Image = []\n",
        "print('Starting to Testing...')\n",
        "for i in range(len(floorplans)):\n",
        "  fp_name = floorplans[i]\n",
        "  fp_path = os.path.join(data_root, fp_name)\n",
        "  fp = FloorPlan(fp_path)\n",
        "  img, rCenters, rTypes, inside, boundary = get_input(fp_path)\n",
        "  fp_rnn.evaluate(img, rCenters, rTypes, inside)\n",
        "\n",
        "  boundary = boundary[:, [1, 0, 2, 3]]\n",
        "  pred_rBoxes = fp_rnn.pred_rBoxes\n",
        "  pred_rBoxes = pred_rBoxes[:, [1, 0, 3, 2]]\n",
        "\n",
        "  layout = get_image(img, pred_rBoxes, rTypes, inside)\n",
        "  living_box, layout, living_mask = obtain_living(layout, boundary)\n",
        "\n",
        "  criterion.get_initial_mutex(pred_rBoxes, boundary)\n",
        "\n",
        "  iter = 0\n",
        "  while get_ratio(layout) > 0.0005 and iter < opt.max_iter:\n",
        "      iter = iter + 1\n",
        "      pred_rBoxes = fine_turning(pred_rBoxes, boundary, living_mask, criterion, opt)\n",
        "      layout = get_image(img, pred_rBoxes, rTypes, inside, living_mask)\n",
        "  image = colorize_mask(layout.numpy())\n",
        "  Image.append(image)\n",
        "  print(fp.name)\n",
        "\n",
        "  fp.update_rBoxes(pred_rBoxes.detach().cpu().numpy())\n",
        "  data = fp.to_dict()\n",
        "  Data.append(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htRfbguo0sRg",
        "outputId": "bbe197ad-730a-4a28-e9a3-aa2a6db1efcd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to Testing...\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Risultati"
      ],
      "metadata": {
        "id": "MMPIbdRe2KvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI_02Xvv1qsR",
        "outputId": "e3974a93-4585-49a8-a7c2-e5ca7cb6b331"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': '0',\n",
              "  'gt_rTypes': array([0, 1, 2, 3, 7, 9]),\n",
              "  'gt_rBoxes': array([[ 14,  55, 101,  92],\n",
              "         [ 80,  36, 110,  62],\n",
              "         [ 26,  57,  41,  72],\n",
              "         [ 65,  36,  78,  53],\n",
              "         [ 43,  36,  63,  62],\n",
              "         [103,  64, 114,  92]]),\n",
              "  'Boundary': array([[ 19,  82,   1,   1],\n",
              "         [ 27,  82,   1,   1],\n",
              "         [ 43,  82,   0,   0],\n",
              "         [ 43,  92,   1,   0],\n",
              "         [114,  92,   2,   0],\n",
              "         [114,  64,   3,   0],\n",
              "         [110,  64,   2,   0],\n",
              "         [110,  36,   3,   0],\n",
              "         [ 43,  36,   0,   0],\n",
              "         [ 43,  57,   3,   0],\n",
              "         [ 26,  57,   0,   0],\n",
              "         [ 26,  74,   3,   0],\n",
              "         [ 14,  74,   0,   0],\n",
              "         [ 14,  82,   1,   0]]),\n",
              "  'rTypes': array([0, 1, 2, 3, 7, 9]),\n",
              "  'rBoxes': array([[0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0]]),\n",
              "  'rCenters': array([[ 58,  71],\n",
              "         [ 93,  48],\n",
              "         [ 33,  65],\n",
              "         [ 72,  43],\n",
              "         [ 53,  47],\n",
              "         [108,  78]])},\n",
              " {'name': '1',\n",
              "  'gt_rTypes': array([0, 1, 2, 3, 5, 7, 9]),\n",
              "  'gt_rBoxes': array([[ 28,  22,  65, 106],\n",
              "         [ 67,  72,  97, 106],\n",
              "         [ 25,  22,  42,  36],\n",
              "         [ 28,  38,  36,  50],\n",
              "         [ 67,  52,  97,  70],\n",
              "         [ 67,  22,  97,  50],\n",
              "         [ 99,  72, 103, 106]]),\n",
              "  'Boundary': array([[ 59, 101,   0,   1],\n",
              "         [ 59, 106,   1,   0],\n",
              "         [103, 106,   2,   0],\n",
              "         [103,  72,   3,   0],\n",
              "         [ 97,  72,   2,   0],\n",
              "         [ 97,  22,   3,   0],\n",
              "         [ 25,  22,   0,   0],\n",
              "         [ 25,  36,   1,   0],\n",
              "         [ 28,  36,   0,   0],\n",
              "         [ 28, 100,   1,   0],\n",
              "         [ 59, 100,   0,   0]]),\n",
              "  'rTypes': array([0, 1, 2, 3, 7, 7]),\n",
              "  'rBoxes': array([[0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0],\n",
              "         [0, 0, 0, 0]]),\n",
              "  'rCenters': array([[64, 69],\n",
              "         [79, 33],\n",
              "         [40, 69],\n",
              "         [36, 52],\n",
              "         [81, 59],\n",
              "         [39, 32]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "sBdZayon2P6B",
        "outputId": "e4e88893-744e-4cf0-9bf7-b7c1a695cbda"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACM0lEQVR4nO3dsUrDUBhA4VTFURScxLcQOvkQ2YsgSgdFHMTFJ3ARBxEFRZfSxSkP4SQW30EcHURwNQ5KFOrQ3Nx6UnO+qdLmNnD4r0pT0srzPBFnij6BpjMAzAAwA8AMADMAzAAwA8AMADMAzAAwA8AMADMAzAAwA8AMADMAzAAwA8AMAJsJPjJN0ypvnGVZlcP/DScAZgBY+BZUOD9cGf3FWweDzwcVdzBcrC3UCYAZABZhCypleL+6uHmfX+2UXefltr8+Oz366xd3Nsq+xa86a9tR1ik4ATADwAwAMwDMADADwAwAMwDMADADwAwAMwDMADADwAwAMwDsrz+QGba/1w05rN19Pr2OfS4AJwBmAJgBYAaAGQBmAJgBYPz/AcFiXWvFihBgbnmz+iKN5RYEm+AtCJGd3H09elxKkiTdbX8/FXTBuhMAMwDMLaict4X7nz/2e1UvWHcCYBEm4PXpqvoiSVP/nHUCYPX6HdDAYarRBBwdX9KnAKhRgGYyAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADAAzAMwAMAPADACL8BWl4t5sEZZ6iLXSoN87i7XWWDkBMAPAwreget6PduJuUekEwAwAq9cXtSOKftPHMXECYAaAtfI8p8+h0ZwAmAFgBoAZAGYAmAFgBoAZAGYAmAFgBoAZAGYAmAFgBoAZAGYAmAFgBoAZAPYByeE6NwXPc5EAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "AmJw_2fI2YT1",
        "outputId": "c0255007-51b0-4c9e-9e0e-b1b86dcf3ff6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAACOUlEQVR4nO3dP0rDUBzA8VScHFzcxBs4KnVz8gCZCqJO/gEdFMTFE7iIUAcdRBBUBKccwBMI0kuIB3AUJA6Fbo2RJu+bF7+fqWBof/D1vWL6pJ08zxNxpugB/jsDwAwAMwDMADADwAwAMwDMADADwKbpAWqRpmn5i7Msq2uOElwBMAPA2rkFjTzeX4370cbWQchJxnEFwAwAMwDMALCWvwkXyC5f6RGSxBWAMwDMALAI3gP+dGMnOq4AmAFgEWxBI/2VZXqE6sUUoFrpYXf4AP04wC2IZgCYAWAGgBkAZgCYAWAGgBkAZgCYAWAGgIW4GdfwT1SKx6v76G5Md0Pvvr6HD06Od9lJKhRTgL1eCzfMoAGuz5ZCvlyxgnO7ScCjuy38nYqLAWAGgBkAZgCYAWAGgBkAZgCYAWAGgBkAZgCYAWAGgBkAZgCYAWAGgBkAZgBY0FMRzx/r5S/e6c7UN0lzuAJgBoAZAGYAmAFgBoAZAGYAmAFgzf0Hjc/32+ILZhe2w0xSK1cAzACwoFtQb/4p5MtFwRUAMwDMADADwAwAMwDMADADwAwAMwDMADADwAwAMwDMADADwAwAMwDMADADwAwAMwDMALDmHk381fnFzdzqIj3FpFwBMAPADAAzAMwAMAPADAAzACzoH2L7p28VP+NgsHa0WfFzhuUKgBkAFmILquPL6Br+7XzlRXwzbuil/0CPMBG3IJgBYJ08z+kZ/jVXAMwAMAPADAAzAMwAMAPADAAzAOwHfQoyasrsIgEAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SALVATAGGIO DATI"
      ],
      "metadata": {
        "id": "WNlZxBpE2LLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomPartition/0.mat\", {\"data\" : Data[0]})\n",
        "sio.savemat(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/RoomPartition/1.mat\", {\"data\" : Data[1]})"
      ],
      "metadata": {
        "id": "zrh2v2--2L29"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image[0].save(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/Output/img0.png\")\n",
        "Image[1].save(\"/content/drive/MyDrive/Colab_Notebooks/Deep_Learning/Progetto/Risultati/Output/img1.png\")"
      ],
      "metadata": {
        "id": "Ev6T-BG33RSL"
      },
      "execution_count": 81,
      "outputs": []
    }
  ]
}